{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "Basic_classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1OrjV8UPSpq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LKaPLBQPSpr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSJlSZV1PSps"
      },
      "source": [
        "##import Libraries\n",
        "import os,shutil\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-0J0F0cPSpu"
      },
      "source": [
        "##Preproces Data-----> From one directory to categorical directory coping data\n",
        "\n",
        "path = 'classification'   ##Dataset Whole images in single directory\n",
        "file_path = 'train_class' ## Destination path where data is categorised using specific class\n",
        "\n",
        "img_file = os.listdir(path)\n",
        "\n",
        "for i in sorted(img_file):\n",
        "    img_class_name = i.split('_')[0] \n",
        "    path1 = path + '/' + i\n",
        "    det_path_dir = file_path +'/'+ img_class_name\n",
        "    if not os.path.isdir(det_path_dir):\n",
        "        os.mkdir(det_path_dir)\n",
        "    shutil.copyfile(path1 ,det_path_dir + '/' + i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83MB7vkQPSpw"
      },
      "source": [
        "\n",
        "## Train and Test Data Paths\n",
        "path_train = 'train_class'    ##Categorised folder for train images\n",
        "path_test = 'test_class'    ##Categorised folder for test images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWXP06KCPSpx"
      },
      "source": [
        "## Create classification model using keras\n",
        "input_shape = (224, 224,3)\n",
        "img_input = keras.layers.Input(shape=input_shape)\n",
        "\n",
        "x = keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same',name='block1_conv1')(img_input)\n",
        "\n",
        "x = keras.layers.Conv2D(32, (3, 3), activation='relu',padding='same',name='block1_conv2')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "x = keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same',name='block2_conv1')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Conv2D(64, (3, 3), activation='relu',padding='same',name='block2_conv2')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "x = keras.layers.Conv2D(128, (3, 3), activation='relu',padding='same',name='block3_conv1')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "x = keras.layers.Flatten(name='flatten')(x)\n",
        "\n",
        "x = keras.layers.Dense(512, activation='relu', name='fc1')(x)\n",
        "x = keras.layers.Dropout(0.2)(x)\n",
        "\n",
        "x = keras.layers.Dense(128, activation='relu', name='fc2')(x)\n",
        "\n",
        "x = keras.layers.Dense(5, activation='softmax', name='predictions')(x)\n",
        "\n",
        "model = keras.models.Model(img_input, x)\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AUVVkAPSpz"
      },
      "source": [
        "## Data Preprocessing and fit on Model\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        path_train,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        path_test,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6c9d51YPSp0"
      },
      "source": [
        "## Compile and fit model\n",
        "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
        "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_generator,\n",
        "        steps_per_epoch=STEP_SIZE_TRAIN,\n",
        "        epochs=50,verbose =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vinv1vr8PSp1"
      },
      "source": [
        "##Evaluate proposed model with test dataset\n",
        "model.evaluate_generator(\n",
        "    validation_generator, steps=STEP_SIZE_VALID)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rubmzlfePSp2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}